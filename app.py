import streamlit as st
import os
import random
import re
from io import BytesIO
import requests
import numpy as np
import pandas as pd
from PIL import Image
import exifread
import pdfplumber
from docx import Document
from google.oauth2 import service_account
from google.cloud import texttospeech
import plotly.express as px
import plotly.graph_objs as go
import streamlit.components.v1 as components
from pydub import AudioSegment

# çœŸã®å§‹å‹•ã€‚  
# æœ¬ã‚³ãƒ¼ãƒ‰ã¯ã€Exifa.net(è‘—:Sahir Maharaj,2024,CC-BY4.0)ç”±æ¥ã‚³ãƒ¼ãƒ‰ã‚’ç™ºå±•çš„ã«ç”¨ã„ã‚‹ã€‚  
# Google TTSã¨EXIFè§£æã€å£®éº—ãªå¯è¦–åŒ–ã€ç²’å­ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ±åˆã—ã€300ãƒšãƒ¼ã‚¸ã‚’è¶…ãˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å®Œå…¨éŸ³å£°åŒ–ã—ã€MP3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¾ã§å¯èƒ½ã¨ã—ãŸä¸–ç•Œåˆã®ç©¶æ¥µWebã‚¢ãƒ—ãƒªã€‚  
# ä»Šã“ãä¸–ç•Œæœ€å…ˆç«¯ã®æŠ€è¡“ã‚’ç·å‹•å“¡ã—ã€ç¥ãŒã‹ã‚Šçš„ãªä½“é¨“ã‚’å®Ÿç¾ã™ã‚‹ã€‚

########################################################
# åˆæœŸè¨­å®š
########################################################
st.set_page_config(page_title="ä¸–ç•Œæœ€å…ˆç«¯ãƒ»çµ±åˆWEBã‚¢ãƒ—ãƒª", page_icon="âœ¨", layout="wide")

# Google Cloud TTSèªè¨¼
if "gcp_service_account" in st.secrets:
    service_account_info = st.secrets["gcp_service_account"]
    credentials = service_account.Credentials.from_service_account_info(service_account_info)
    tts_client = texttospeech.TextToSpeechClient(credentials=credentials)
else:
    st.error("Google Cloudã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ãŒst.secretsã«ã‚ã‚Šã¾ã›ã‚“ã€‚è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ã“ã“ã¯çœŸãªã‚‹æ–°ä¸–ç•Œã€‚ã‚ãªãŸã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚„ç”»åƒã‚’è§£æã—ã€éŸ³å£°åŒ–ã—ã€å¯è¦–åŒ–ã™ã‚‹ã€å…¨ã¦ãŒå¯èƒ½ãªç©¶æ¥µã®ä¸€ãƒšãƒ¼ã‚¸ã§ã™ã€‚"}]
if "exif_df" not in st.session_state:
    st.session_state["exif_df"] = pd.DataFrame()
if "image_url" not in st.session_state:
    st.session_state["image_url"] = ""
if "uploaded_files" not in st.session_state:
    st.session_state["uploaded_files"] = None

########################################################
# å¹»æƒ³çš„ç²’å­èƒŒæ™¯
########################################################
particles_js = """<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>Particles.js</title>
<style>
#particles-js {
  position: fixed;
  width:100vw;
  height:100vh;
  top:0;left:0;z-index:-1;
  background:#000;
}
.content {
  position:relative;z-index:1;color:white;
}
</style>
</head>
<body>
<div id="particles-js"></div>
<div class="content"></div>
<script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
<script>
particlesJS("particles-js", {
  "particles":{
    "number":{"value":300,"density":{"enable":true,"value_area":800}},
    "color":{"value":"#ffffff"},
    "shape":{"type":"circle","stroke":{"width":0,"color":"#000000"}},
    "opacity":{"value":0.5,"random":false},
    "size":{"value":2,"random":true},
    "line_linked":{"enable":true,"distance":100,"color":"#ffffff","opacity":0.22,"width":1},
    "move":{"enable":true,"speed":0.2,"direction":"none","random":false,"straight":false,"out_mode":"out","bounce":true}
  },
  "interactivity":{
    "events":{
      "onhover":{"enable":true,"mode":"grab"},
      "onclick":{"enable":true,"mode":"repulse"},
      "resize":true
    },
    "modes":{
      "grab":{"distance":100,"line_linked":{"opacity":1}},
      "bubble":{"distance":400,"size":2,"duration":2,"opacity":0.5,"speed":1},
      "repulse":{"distance":200,"duration":0.4},
      "push":{"particles_nb":2},
      "remove":{"particles_nb":3}
    }
  },
  "retina_detect":true
});
</script>
</body>
</html>
"""
components.html(particles_js, height=0, width=0)

########################################################
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ç¾¤
########################################################
def clear_url():
    st.session_state["image_url"] = ""

def clear_files():
    st.session_state["uploaded_files"] = None
    st.session_state["file_uploader_key"] = not st.session_state.get("file_uploader_key", False)

def clear_chat_history():
    st.session_state["messages"] = [{"role":"assistant","content":"ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚¯ãƒªã‚¢ã•ã‚Œã¾ã—ãŸã€‚ã“ã‚ŒãŒå†ã³æ–°ãŸãªä¸–ç•Œã®å§‹ã¾ã‚Šã§ã™ã€‚"}]
    st.session_state["exif_df"] = pd.DataFrame()
    st.session_state["uploaded_files"] = None
    st.session_state["image_url"] = ""
    st.cache_data.clear()
    st.success("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼")

def load_image(file):
    if isinstance(file, str):
        response = requests.get(file)
        response.raise_for_status()
        return Image.open(BytesIO(response.content))
    elif isinstance(file, bytes):
        return Image.open(BytesIO(file))
    else:
        return Image.open(file)

def clear_exif_data(image_input):
    if isinstance(image_input, BytesIO):
        image_input.seek(0)
        image = Image.open(image_input)
    elif isinstance(image_input, Image.Image):
        image = image_input
    else:
        raise ValueError("ç”»åƒã‚¿ã‚¤ãƒ—ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
    data = list(image.getdata())
    image_without_exif = Image.new(image.mode, image.size)
    image_without_exif.putdata(data)

    buffered = BytesIO()
    image_without_exif.save(buffered, format="JPEG", quality=100, optimize=True)
    buffered.seek(0)
    return buffered.getvalue()

def download_image(data):
    st.download_button(
        label="â‡© EXIFé™¤å»å¾Œã®ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=data,
        file_name="image_no_exif.jpg",
        mime="image/jpeg",
    )

def detect_language(text):
    # ç°¡æ˜“çš„åˆ¤å®šï¼šæ—¥æœ¬èªæ–‡å­—å«æœ‰ã§ja-JPã€ãã‚Œä»¥å¤–en-US
    if re.search('[\u3000-\u303F\u3040-\u309F\u30A0-\u30FF]', text):
        return 'ja-JP'
    return 'en-US'

def synthesize_speech_chunk(text, lang_code, gender='neutral'):
    # 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§å‡¦ç†ã§ãã‚‹é•·ã•: ç´„5000æ–‡å­—ç¨‹åº¦æ¨å¥¨
    # å®‰å…¨ã®ãŸã‚4500æ–‡å­—ç¨‹åº¦ã§ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    max_chars = 4500
    chunks = [text[i:i+max_chars] for i in range(0,len(text),max_chars)]

    gender_map = {
        'default': texttospeech.SsmlVoiceGender.SSML_VOICE_GENDER_UNSPECIFIED,
        'male': texttospeech.SsmlVoiceGender.MALE,
        'female': texttospeech.SsmlVoiceGender.FEMALE,
        'neutral': texttospeech.SsmlVoiceGender.NEUTRAL
    }

    combined_audio = AudioSegment.empty()

    for i, chunk in enumerate(chunks):
        synthesis_input = texttospeech.SynthesisInput(text=chunk)
        voice = texttospeech.VoiceSelectionParams(
            language_code=lang_code,
            ssml_gender=gender_map.get(gender, texttospeech.SsmlVoiceGender.NEUTRAL)
        )
        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
        response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)

        # BytesIOã‹ã‚‰AudioSegmentã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰
        segment = AudioSegment.from_file(BytesIO(response.audio_content), format="mp3")
        combined_audio += segment

    # æœ€çµ‚çš„ãªMP3ã‚’ã¾ã¨ã‚ã¦è¿”ã™
    output_buffer = BytesIO()
    combined_audio.export(output_buffer, format="mp3")
    output_buffer.seek(0)
    return output_buffer

########################################################
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
########################################################
with st.sidebar:
    st.markdown("<h1 style='color:white;'>ä¸–ç•Œå…ˆç«¯èåˆ</h1>",unsafe_allow_html=True)
    st.markdown("#### EXIFè§£æ & è¶…å¤§è¦æ¨¡TTSå¯¾å¿œã‚¢ãƒ—ãƒª")
    expander = st.expander("ğŸ—€ ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›")
    with expander:
        st.text("é•·å¤§ãªãƒ†ã‚­ã‚¹ãƒˆã‚„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€URLæŒ‡å®šå¯èƒ½")
        image_url = st.text_input("EXIFè§£æç”¨ã®ç”»åƒURL:", key="image_url", on_change=clear_files, value=st.session_state["image_url"])
        file_uploader_key = "file_uploader_{}".format(st.session_state.get("file_uploader_key", False))
        uploaded_files = st.file_uploader(
            "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰:",
            type=["txt","pdf","docx","csv","jpg","png","jpeg"],
            key=file_uploader_key,
            on_change=clear_url,
            accept_multiple_files=True,
        )
        if uploaded_files is not None:
            st.session_state["uploaded_files"] = uploaded_files

    st.markdown("---")
    st.button("ğŸ—‘ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢", on_click=clear_chat_history)
    st.markdown("---")
    st.caption("ã‚³ãƒ¼ãƒ‰ã¯Exifa.net(2024, Sahir Maharaj)ç”±æ¥(CC-BY 4.0)")

########################################################
# ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼†EXIFè§£æ
########################################################
file_text = ""
if st.session_state["uploaded_files"]:
    for uf in st.session_state["uploaded_files"]:
        if uf.type == "application/pdf":
            with pdfplumber.open(uf) as pdf:
                pages = [page.extract_text() for page in pdf.pages]
            file_text = "\n".join(p for p in pages if p)
        elif uf.type == "text/plain":
            file_text = str(uf.read(), "utf-8")
        elif uf.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            doc = Document(uf)
            file_text = "\n".join([para.text for para in doc.paragraphs])
        elif uf.type == "text/csv":
            df = pd.read_csv(uf)
            file_text = df.to_string(index=False)
        elif uf.type in ["image/jpeg","image/png","image/jpg"]:
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False) as temp:
                temp.write(uf.read())
                temp.flush()
                temp.close()
                with open(temp.name,"rb") as f:
                    tags = exifread.process_file(f)
                os.unlink(temp.name)
            exif_data = {}
            for tag in tags.keys():
                if tag not in ["JPEGThumbnail","TIFFThumbnail","Filename","EXIF MakerNote"]:
                    exif_data[tag] = str(tags[tag])
            df = pd.DataFrame(exif_data, index=[0])
            df.insert(loc=0, column="Image Feature", value=["Value"]*len(df))
            df = df.transpose()
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            st.session_state["exif_df"] = df
            file_text = file_text or "\n".join([f"{tag}: {tags[tag]}" for tag in tags.keys() if tag not in ("JPEGThumbnail","TIFFThumbnail","Filename","EXIF MakerNote")])

if st.session_state["image_url"]:
    try:
        resp_head = requests.head(st.session_state["image_url"])
        if resp_head.headers.get("Content-Type","").startswith("image"):
            resp = requests.get(st.session_state["image_url"])
            resp.raise_for_status()
            image_data = BytesIO(resp.content)
            image = Image.open(image_data)
            image.load()
            tags = exifread.process_file(image_data)
            exif_data = {}
            for tag in tags.keys():
                if tag not in ["JPEGThumbnail","TIFFThumbnail","Filename","EXIF MakerNote"]:
                    exif_data[tag] = str(tags[tag])
            df = pd.DataFrame(exif_data, index=[0])
            df.insert(loc=0, column="Image Feature", value=["Value"]*len(df))
            df = df.transpose()
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            st.session_state["exif_df"] = df
        else:
            st.warning("URLã¯ç”»åƒã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    except:
        st.warning("ç”»åƒã‚’URLã‹ã‚‰å–å¾—ã§ãã¾ã›ã‚“ã€‚")

########################################################
# ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
########################################################
st.markdown("<h1 style='text-align:center;color:white;'>çœŸã«ä¸–ç•Œæœ€å…ˆç«¯ã®EXIF & TTS çµ±åˆWEBã‚¢ãƒ—ãƒª</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;color:#cccccc;'>300ãƒšãƒ¼ã‚¸è¶…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°åŒ–ã€EXIFè§£æã€å¹»æƒ³çš„å¯è¦–åŒ–ã€å…¨ã¦ã‚’ä¸€åº¦ã«å®Ÿç¾ã€‚</p>",unsafe_allow_html=True)

tabs = st.tabs(["ğŸ“œ éŸ³å£°åˆæˆï¼ˆå¤§è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼‰", "ğŸ–¼ EXIFè§£æï¼†ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«", "ğŸ’¬ å¯¾è©±ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"])

# éŸ³å£°åˆæˆã‚¿ãƒ–
with tabs[0]:
    st.subheader("è¶…å¤§è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸¸ã”ã¨éŸ³å£°åŒ–")
    input_option = st.selectbox("å…¥åŠ›æ–¹æ³•",("ç›´æ¥å…¥åŠ›","ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚­ã‚¹ãƒˆåˆ©ç”¨"))
    tts_text = ""
    if input_option == "ç›´æ¥å…¥åŠ›":
        tts_text = st.text_area("éŸ³å£°åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ","ã“ã“ã«è†¨å¤§ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ä¸‹ã•ã„ã€‚ï¼ˆä¾‹ï¼š300ãƒšãƒ¼ã‚¸åˆ†ã®æ›¸ç±å…¨æ–‡ï¼‰")
    else:
        if file_text:
            st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:")
            st.write(file_text[:500]+"...") #ä¸€éƒ¨ã®ã¿è¡¨ç¤º
            tts_text = file_text
        else:
            st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    selected_gender = st.selectbox("è©±è€…ã®æ€§åˆ¥",('default','male','female','neutral'))
    if tts_text and st.button("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¨ã¦éŸ³å£°åŒ–ã—ã¦MP3ç”Ÿæˆ"):
        with st.spinner("éŸ³å£°åˆæˆä¸­...ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã„å ´åˆã€æ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™"):
            lang_code = detect_language(tts_text)
            final_mp3 = synthesize_speech_chunk(tts_text, lang_code, gender=selected_gender)
        st.success("éŸ³å£°åˆæˆå®Œäº†ï¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™ã€‚")
        st.download_button("ç”Ÿæˆã•ã‚ŒãŸMP3ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=final_mp3, file_name="converted_book.mp3", mime="audio/mpeg")

# EXIFè§£æï¼†ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¿ãƒ–
with tabs[1]:
    st.subheader("EXIFè§£æ & é«˜åº¦å¯è¦–åŒ–")
    if st.session_state["exif_df"].empty and not st.session_state["image_url"]:
        st.info("EXIFãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        st.markdown("##### æŠ½å‡ºã•ã‚ŒãŸEXIFãƒ‡ãƒ¼ã‚¿")
        st.dataframe(st.session_state["exif_df"])
        image_to_analyze = None
        if st.session_state["uploaded_files"]:
            for f in st.session_state["uploaded_files"]:
                if f.type in ["image/jpeg","image/png","image/jpg"]:
                    image_to_analyze = load_image(f)
                    break
        elif st.session_state["image_url"]:
            image_to_analyze = load_image(st.session_state["image_url"])

        if image_to_analyze:
            st.image(image_to_analyze, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_column_width=True)
            data = np.array(image_to_analyze)

            exp1 = st.expander("â›† RGBãƒãƒ£ãƒ³ãƒãƒ«èª¿æ•´")
            with exp1:
                channels = st.multiselect("ãƒãƒ£ãƒ³ãƒãƒ«é¸æŠ",["Red","Green","Blue"],default=["Red","Green","Blue"])
                if channels:
                    cmap = {"Red":0,"Green":1,"Blue":2}
                    selected_idx = [cmap[ch] for ch in channels]
                    ch_data = np.zeros_like(data)
                    for idx in selected_idx:
                        ch_data[:,:,idx] = data[:,:,idx]
                    st.image(Image.fromarray(ch_data), use_column_width=True)
                else:
                    st.image(image_to_analyze, use_column_width=True)

            exp2 = st.expander("ã€½ HSVãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ")
            with exp2:
                hsv_image = image_to_analyze.convert("HSV")
                hsv_data = np.array(hsv_image)
                hue_hist, _ = np.histogram(hsv_data[:,:,0], bins=256, range=(0,256))
                sat_hist, _ = np.histogram(hsv_data[:,:,1], bins=256, range=(0,256))
                val_hist, _ = np.histogram(hsv_data[:,:,2], bins=256, range=(0,256))
                hsv_histogram_df = pd.DataFrame({"Hue":hue_hist,"Saturation":sat_hist,"Value":val_hist})
                st.line_chart(hsv_histogram_df)

            exp3 = st.expander("â˜„ ã‚«ãƒ©ãƒ¼åˆ†å¸ƒã‚µãƒ³ãƒãƒ¼ã‚¹ãƒˆ")
            with exp3:
                red, green, blue = data[:,:,0], data[:,:,1], data[:,:,2]
                ci = {"color":[],"intensity":[],"count":[]}
                for name,channel in zip(["Red","Green","Blue"],[red,green,blue]):
                    unique, counts = np.unique(channel, return_counts=True)
                    ci["color"].extend([name]*len(unique))
                    ci["intensity"].extend(unique)
                    ci["count"].extend(counts)
                cdf = pd.DataFrame(ci)
                fig = px.sunburst(cdf,path=["color","intensity"],values="count",color="color",
                                  color_discrete_map={"Red":"#ff6666","Green":"#85e085","Blue":"#6666ff"})
                st.plotly_chart(fig,use_container_width=True)

            exp4 = st.expander("ğŸ•¸ 3Dã‚«ãƒ©ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹")
            with exp4:
                skip = 8
                sample = data[::skip,::skip].reshape(-1,3)
                fig = go.Figure(data=[go.Scatter3d(
                    x=sample[:,0],y=sample[:,1],z=sample[:,2],
                    mode="markers",
                    marker=dict(size=3,color=["rgb({},{},{})".format(r,g,b) for r,g,b in sample])
                )])
                fig.update_layout(scene=dict(xaxis_title="Red",yaxis_title="Green",zaxis_title="Blue"))
                st.plotly_chart(fig, use_container_width=True)

            st.markdown("#### EXIFé™¤å»å¾Œç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            cleaned = clear_exif_data(image_to_analyze)
            download_image(cleaned)

        # ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆé™çš„ä¾‹ã ãŒã€å°†æ¥LLMå¯¾å¿œã§å‹•çš„ã«å¯èƒ½ï¼‰
        if not st.session_state["exif_df"].empty:
            commentary = """
            ã“ã®EXIFãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ’®å½±è€…ã®ä½¿ç”¨æ©Ÿæã‚„æ’®å½±è¨­å®šãŒã†ã‹ãŒãˆã¾ã™ã€‚éœ²å‡ºã‚„ç„¦ç‚¹è·é›¢ã‹ã‚‰ã€æ’®å½±è€…ã¯ä¸­ç´šã‚¯ãƒ©ã‚¹ã®ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã€  
            è‡ªç„¶å…‰ä¸‹ã¾ãŸã¯é©åˆ‡ãªç…§æ˜ç’°å¢ƒã§ã®æ’®å½±ãŒæ¨æ¸¬ã•ã‚Œã¾ã™ã€‚GPSæƒ…å ±ã®æœ‰ç„¡ã‹ã‚‰ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã‹å±‹å†…æ’®å½±ã‹ãŒæƒ³å®šã§ãã¾ã™ã€‚  
            å…¨ä½“ã¨ã—ã¦ã€ç¨‹ã‚ˆã„çµŒé¨“ã¨äºˆç®—ã‚’æŒã¤å†™çœŸå®¶ã«ã‚ˆã‚‹è¨ˆç”»çš„ãªæ’®å½±ã®æˆæœã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚
            """
            st.markdown("#### è‡ªå‹•ç”Ÿæˆã‚³ãƒ¡ãƒ³ãƒˆ")
            st.write(commentary)
            if st.button("ã‚³ãƒ¡ãƒ³ãƒˆéŸ³å£°å†ç”Ÿ"):
                lang_code = detect_language(commentary)
                audio_data = synthesize_speech_chunk(commentary, lang_code)
                st.audio(audio_data, format="audio/mp3")

# å¯¾è©±ã‚¿ãƒ–
with tabs[2]:
    st.subheader("AIã¨ã®å¯¾è©±")
    for msg in st.session_state["messages"]:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    user_input = st.chat_input("EXIFã‚„TTSã€ç”»åƒè‰²è§£æãªã©è‡ªç”±ã«è³ªå•ã—ã¦ãã ã•ã„...")
    if user_input:
        st.session_state["messages"].append({"role":"user","content":user_input})
        with st.chat_message("user"):
            st.write(user_input)
        # ç¾çŠ¶ç°¡æ˜“å¿œç­”ã€‚å°†æ¥LLMçµ±åˆã§é«˜åº¦å¿œç­”å¯èƒ½
        response = "ç¾æ®µéšã§ã¯ç°¡æ˜“å¿œç­”ã§ã™ã€‚å°†æ¥çš„ã«LLMçµ±åˆã§ã‚ˆã‚Šçš„ç¢ºãªå›ç­”ã‚’æä¾›äºˆå®šã€‚"
        st.session_state["messages"].append({"role":"assistant","content":response})
        with st.chat_message("assistant"):
            st.write(response)

st.markdown("---")
st.caption("ã‚³ãƒ¼ãƒ‰å…ƒ: Exifa.net (Sahir Maharaj,2024), CC-BY 4.0. çœŸãªã‚‹å§‹å‹•ã€ä¸–ç•Œåˆã®çµ±åˆã‚¢ãƒ—ãƒªã¸ã‚ˆã†ã“ãã€‚")
